{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bf8eeb4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Simple Gen AI App using LangChain and OpenAI\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "\n",
    "os.environ[\"openai_api_key\"] = os.getenv(\"OPENAI_API_KEY\")\n",
    "os.environ[\"langchain_api_key\"] = os.getenv(\"LANGCHAIN_API_KEY\")\n",
    "os.environ[\"langchain_tracing_v2\"] = \"true\"\n",
    "os.environ[\"langchain_project\"] = os.getenv(\"LANGCHAIN_PROJECT\", \"GenAIappWithOPENAI\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2aac1c11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Concepts | ü¶úÔ∏èüõ†Ô∏è LangSmith\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Skip to main contentOur Building Ambient Agents with LangGraph course is now available on LangChain Academy!API ReferenceRESTPythonJS/TSSearchRegionUSEUGo to AppGet StartedObservabilityEvaluationPrompt EngineeringDeployment (LangGraph Platform)AdministrationTutorialsOptimize tracing spend on LangSmithHow-to GuidesSetupConceptual GuideSelf-hostingPricingReferenceCloud architecture and scalabilityAuthz and AuthnAuthentication methodsdata_formatsEvaluationData\n"
     ]
    }
   ],
   "source": [
    "##Data injestion\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "loader = WebBaseLoader(\"https://docs.smith.langchain.com/administration/concepts\")\n",
    "docs=loader.load()\n",
    "print(docs[0].page_content[:500])  # Print the first 500 characters of the first document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b8349853",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concepts | ü¶úÔ∏èüõ†Ô∏è LangSmith\n"
     ]
    }
   ],
   "source": [
    "##load data to chunk        \n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "recursive_text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000,chunk_overlap=200)\n",
    "\n",
    "docs = recursive_text_splitter.split_documents(docs)\n",
    "print(docs[0].page_content[:5000])  # Print the first 500 characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "36ffe36f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama import OllamaEmbeddings\n",
    "embeddings = OllamaEmbeddings(model=\"llama2\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cd90151c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import FAISS\n",
    "db = FAISS.from_documents(docs, embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "612fc764",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langchain_community.vectorstores.faiss.FAISS at 0x1beb5652080>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "824ec042",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Feedback is added to any run on the trace\\nAn Annotation Queue receives any run from the trace\\nA Run Rule matches any run within a trace\\n\\nWhy auto-upgrade traces?\\nWe have two reasons behind the auto-upgrade model for tracing:\\n\\nWe think that traces that match any of these conditions are fundamentally more interesting than other traces, and\\ntherefore it is good for users to be able to keep them around longer.\\nWe philosophically want to charge customers an order of magnitude lower for traces that may not be interacted with meaningfully.\\nWe think auto-upgrades align our pricing model with the value that LangSmith brings, where only traces with meaningful interaction\\nare charged at a higher rate.\\n\\nIf you have questions or concerns about our pricing model, please feel free to reach out to support@langchain.dev and let us know your thoughts!\\nHow does data retention affect downstream features?'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"What is the purpose of LangSmith?\"\n",
    "docs = db.similarity_search(query, k=3)\n",
    "docs[0].page_content  # Print the first 500 characters of the first document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a493830c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama import OllamaLLM\n",
    "llm = OllamaLLM(model=\"llama2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "021e81b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "# Create a proper chat prompt template\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a helpful assistant.\"),\n",
    "    (\"user\", \"Answer the following question based only on the provided context. If you don't know the answer, just say that you don't know, don't try to make up an answer.\\n\\nContext: {context}\")\n",
    "])\n",
    "\n",
    "# Create a document chain using your LLM and the prompt\n",
    "document_chain = create_stuff_documents_chain(llm, prompt)\n",
    "\n",
    "# Optional: combine with another component (if desired)\n",
    "# Here you're chaining the document_chain directly with the LLM, which is unnecessary if create_stuff_documents_chain already handles it.\n",
    "# You can just use document_chain directly like this:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2b3f9e8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The auto-upgrade traces feature is implemented to enhance the user experience and provide better value for customers. By automatically upgrading traces that match certain conditions, such as having more interesting or meaningful interactions, LangSmith can offer a pricing model that aligns with the value it brings to its users. This means that traces that are more relevant or engaging to users will be charged at a lower rate, while traces with less meaningful interaction will be charged at a higher rate.\n",
      "\n",
      "Data retention, on the other hand, affects downstream features by determining how long tracing data is kept available for analysis and use. A longer data retention period allows users to access and analyze more historical data, which can provide valuable insights into trends and patterns over time. This can be particularly useful for tasks such as:\n",
      "\n",
      "* Identifying seasonal or long-term trends in user behavior\n",
      "* Tracking the effectiveness of marketing campaigns over time\n",
      "* Monitoring changes in user demographics or preferences\n",
      "\n",
      "By offering more data retention options, LangSmith can help users make better decisions and optimize their strategies based on a larger and more comprehensive view of user behavior.\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.documents import Document\n",
    "response = document_chain.invoke({\"context\": docs, \"question\": \"What is the purpose of LangSmith?\"})\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b0b18b28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input': 'What is the purpose of LangSmith?', 'context': [Document(id='e6408e29-f7e6-475c-8fca-421bd4414335', metadata={'source': 'https://docs.smith.langchain.com/administration/concepts', 'title': 'Concepts | ü¶úÔ∏èüõ†Ô∏è LangSmith', 'description': 'This conceptual guide covers topics related to managing users, organizations, and workspaces within LangSmith.', 'language': 'en'}, page_content='Feedback is added to any run on the trace\\nAn Annotation Queue receives any run from the trace\\nA Run Rule matches any run within a trace\\n\\nWhy auto-upgrade traces?\\nWe have two reasons behind the auto-upgrade model for tracing:\\n\\nWe think that traces that match any of these conditions are fundamentally more interesting than other traces, and\\ntherefore it is good for users to be able to keep them around longer.\\nWe philosophically want to charge customers an order of magnitude lower for traces that may not be interacted with meaningfully.\\nWe think auto-upgrades align our pricing model with the value that LangSmith brings, where only traces with meaningful interaction\\nare charged at a higher rate.\\n\\nIf you have questions or concerns about our pricing model, please feel free to reach out to support@langchain.dev and let us know your thoughts!\\nHow does data retention affect downstream features?'), Document(id='44888139-7cd4-42ad-8cf8-277658eade70', metadata={'source': 'https://docs.smith.langchain.com/administration/concepts', 'title': 'Concepts | ü¶úÔ∏èüõ†Ô∏è LangSmith', 'description': 'This conceptual guide covers topics related to managing users, organizations, and workspaces within LangSmith.', 'language': 'en'}, page_content='A workspace is a logical grouping of users and resources within an organization. A workspace separates trust boundaries for resources and access control.\\nUsers may have permissions in a workspace that grant them access to the resources in that workspace, including tracing projects, datasets, annotation queues, and prompts. For more details, see the setup guide.\\nIt is recommended to create a separate workspace for each team within your organization. To organize resources even further, you can use Resource Tags to group resources within a workspace.\\nThe following image shows a sample workspace settings page:'), Document(id='b31b50a5-d0b5-4501-81f6-67abbd2396d1', metadata={'source': 'https://docs.smith.langchain.com/administration/concepts', 'title': 'Concepts | ü¶úÔ∏èüõ†Ô∏è LangSmith', 'description': 'This conceptual guide covers topics related to managing users, organizations, and workspaces within LangSmith.', 'language': 'en'}, page_content='Billing model\\u200b\\nBillable metrics\\nOn your LangSmith invoice, you will see two metrics that we charge for:\\n\\nLangSmith Traces (Base Charge)\\nLangSmith Traces (Extended Data Retention Upgrades).'), Document(id='52485484-5b9c-4e4c-8269-13ec672210e5', metadata={'source': 'https://docs.smith.langchain.com/administration/concepts', 'title': 'Concepts | ü¶úÔ∏èüõ†Ô∏è LangSmith', 'description': 'This conceptual guide covers topics related to managing users, organizations, and workspaces within LangSmith.', 'language': 'en'}, page_content='The following diagram explains the relationship between organizations, workspaces, and the different resources scoped to and within a workspace:')], 'answer': \"To answer your question, I must interpret the provided context and information. Based on the given details, here's my understanding of why auto-upgrading traces is beneficial:\\n\\nAuto-upgrading traces helps to retain interesting traces for users longer, as the two reasons behind the auto-upgrade model suggest. By keeping these traces around, users can interact with them more meaningfully and potentially unlock additional value from LangSmith's features.\\n\\nMoreover, the pricing model is designed to align with the value that LangSmith brings. Charging customers an order of magnitude lower for traces that may not be interacted with meaningfully encourages users to focus on the most valuable traces while reducing costs. This approach incentivizes users to keep interesting traces around longer and use them more extensively, ultimately driving better outcomes and ROI for their organizations.\\n\\nIn terms of data retention affecting downstream features, a workspace serves as a logical grouping of users and resources within an organization. Users can have permissions in a workspace that grant access to tracing projects, datasets, annotation queues, and prompts. By organizing resources using Resource Tags, users can further categorize and manage them within a workspace.\\n\\nHowever, it's important to note that the billing model charges for two metrics: LangSmith Traces (Base Charge) and LangSmith Traces (Extended Data Retention Upgrades). The extended data retention upgrade is essential because it allows users to retain traces longer and access their extended data, which can provide additional value.\\n\\nIn summary, auto-upgrading traces helps users interact more meaningfully with valuable resources, aligns pricing with the value LangSmith brings, and enables better outcomes and ROI for organizations by organizing and managing resources within workspaces using Resource Tags.\"}\n"
     ]
    }
   ],
   "source": [
    "vectorstore = db.as_retriever()\n",
    "from langchain.chains import create_retrieval_chain\n",
    "retrieval_chain = create_retrieval_chain(vectorstore, document_chain)\n",
    "\n",
    "response = retrieval_chain.invoke({\"input\": \"What is the purpose of LangSmith?\"})\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf906541",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
